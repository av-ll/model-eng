# import some required librariesimport pandas as pdimport numpy as np# read the datadata = pd.read_csv('data-task-1.csv')# we can check the number of rowsprint("\nNumber of rows : " + str(len(data))+"\n")# we can check the number of columnsprint("Number of columns :" + str(len(data.columns))+"\n")print("Initial dataset datatypes : \n")print(data.dtypes,"\n")data.drop(['Unnamed: 32','id'],axis=1,inplace=True)# perform the Turkey Test for out# calculate the data quantilesdata_quantiles = data.quantile(q=[0.25, 0.75], axis=0, numeric_only=True, interpolation='midpoint')# retrieve only numerical columnsdata_numerical_columns = data.drop(['diagnosis'],axis=1).columns# calculate inter-quartile rangeIQR = [{x:(data_quantiles[x][0.75] - data_quantiles[x][0.25])} for x in data_numerical_columns]# calculate number of outliers with Turkeys method# with 2.2 multiplier based on #“Fine-Tuning Some Resistant Rules for Outlier Labeling” by Hoaglin and Iglewicz (1987).outliers_count = {}i = 0for column in data_numerical_columns:        outliers = 0            for datapoint in np.asarray(data[column]):                if datapoint < (data_quantiles[column][0.25]-IQR[i][column]*2.2) or datapoint > (data_quantiles[column][0.75]+IQR[i][column]*2.2):                        outliers += 1    outliers_count[column] = outliers    i +=1                    # using this method we can count the number of possible outliers and consider # regularization perhaps in the future# let's analize the target featuretarget_feature = data['diagnosis']# No null and no duplicate valuesprint("No null values:\n")print(data.isnull().sum())print('\nNumber of duplicate values:\n',data.duplicated().sum())print('Unique values dependent variable: \n',target_feature.unique())import seaborn as snsimport matplotlib.pyplot as pltsns.set_theme(style="dark")plot = sns.countplot(target_feature,x=target_feature,palette=sns.color_palette(['crimson', 'forestgreen']),orient='h')plot.set(title='Count of Benign vs Malign datapoints')plot.bar_label(plot.containers[0])plt.savefig('count_plot_y.jpg')# from the plot we see there is an imbalancd dataset so we have to mind that# we apply onehot and it does not really matter in this case label # or one hot encoding as both produce the same resultfrom sklearn.preprocessing import OneHotEncoderonehot = OneHotEncoder(drop='if_binary')diagnose = onehot.fit_transform(data[['diagnosis']].to_numpy())data['diagnose'] = diagnose.toarray()data.drop(['diagnosis'],axis=1,inplace=True)data.to_csv('prepared_data.csv',index=False)